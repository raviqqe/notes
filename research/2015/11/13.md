# Research notes

Posted on: 2015/11/13


## Training of document and sentence vectors

Document and sentence vectors are generated by hassygo's paragraph vector
implementation currently. While I set the number of iterations to around 20
which is estimated from the experience with mori's vLBL+vLBL(c),
it uses not a complex, modern optimizer but SGD.
So, more iterations for training would be needed with it.


## Evaluation of weighted average of sentence vectors

The experiments that evaluate weighted average of sentence vectors are done.
Assuming that one document has some sections whose order expresses some story,
the sentence vectors are averaged and compressed into section vectors
with weights for each section vector. The weight function shapes a triangle
and will be replaced with something which seems authentic,
such as Bezier basis function, in the future (if the method succeeds).

The result is below. The first column shows the number of sections
which indicates how many vectors sentence vectors are compressed into.
The second column shows the accuracies for each.


number of sections | accuracy
-------------------|--------------------
1 (total mean)     | 0.45737141370773315
2                  | 0.46284303069114685
4                  | 0.46399992704391480
